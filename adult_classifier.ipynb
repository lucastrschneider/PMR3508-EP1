{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit9838909551d74a6aa782184662a5b61b",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMR3508 - Aprendizado de Máquina e Reconhecimento de Padrões\n",
    "Análise e classificação com a base de dados [Adult](https://www.kaggle.com/c/adult-pmr3508), disponível também em [UCI Repository](https://archive.ics.uci.edu/ml/index.php).\n",
    "\n",
    "Autor: Lucas Tonini Rosenberg Schneider\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Inicialização\n",
    "\n",
    "### 1.1 Importando pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing as prep\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = ['ID', 'Age', 'Workclass', 'Final Weight', 'Education', 'Education Num', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital Gain', 'Capital Loss', 'Hours per Week', 'Native Country']\n",
    "y_column = ['Income']\n",
    "\n",
    "train_data_raw = pd.read_csv('data/train_data.csv', names = (x_columns + y_column), na_values = '?', header = 0)\n",
    "test_data_raw = pd.read_csv('data/test_data.csv', names = x_columns, na_values = '?', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data_raw.shape)\n",
    "train_data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2 Análise e compreensão\n",
    "\n",
    "### 2.1 Dados Numéricos\n",
    "\n",
    "A seguir, serão discutidos os dados numéricos mais relevantes, cuja compreensão ajuda a entender melhor o problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 ID           Age  Final Weight  Education Num  Capital Gain  \\\ncount  32560.000000  32560.000000  3.256000e+04   32560.000000  32560.000000   \nmean   32559.500000     38.581634  1.897818e+05      10.080590   1077.615172   \nstd     9399.406719     13.640642  1.055498e+05       2.572709   7385.402999   \nmin    16280.000000     17.000000  1.228500e+04       1.000000      0.000000   \n25%    24419.750000     28.000000  1.178315e+05       9.000000      0.000000   \n50%    32559.500000     37.000000  1.783630e+05      10.000000      0.000000   \n75%    40699.250000     48.000000  2.370545e+05      12.000000      0.000000   \nmax    48839.000000     90.000000  1.484705e+06      16.000000  99999.000000   \n\n       Capital Loss  Hours per Week  \ncount  32560.000000    32560.000000  \nmean      87.306511       40.437469  \nstd      402.966116       12.347618  \nmin        0.000000        1.000000  \n25%        0.000000       40.000000  \n50%        0.000000       40.000000  \n75%        0.000000       45.000000  \nmax     4356.000000       99.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>Final Weight</th>\n      <th>Education Num</th>\n      <th>Capital Gain</th>\n      <th>Capital Loss</th>\n      <th>Hours per Week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>32560.000000</td>\n      <td>32560.000000</td>\n      <td>3.256000e+04</td>\n      <td>32560.000000</td>\n      <td>32560.000000</td>\n      <td>32560.000000</td>\n      <td>32560.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>32559.500000</td>\n      <td>38.581634</td>\n      <td>1.897818e+05</td>\n      <td>10.080590</td>\n      <td>1077.615172</td>\n      <td>87.306511</td>\n      <td>40.437469</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9399.406719</td>\n      <td>13.640642</td>\n      <td>1.055498e+05</td>\n      <td>2.572709</td>\n      <td>7385.402999</td>\n      <td>402.966116</td>\n      <td>12.347618</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>16280.000000</td>\n      <td>17.000000</td>\n      <td>1.228500e+04</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>24419.750000</td>\n      <td>28.000000</td>\n      <td>1.178315e+05</td>\n      <td>9.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>32559.500000</td>\n      <td>37.000000</td>\n      <td>1.783630e+05</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>40699.250000</td>\n      <td>48.000000</td>\n      <td>2.370545e+05</td>\n      <td>12.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>45.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>48839.000000</td>\n      <td>90.000000</td>\n      <td>1.484705e+06</td>\n      <td>16.000000</td>\n      <td>99999.000000</td>\n      <td>4356.000000</td>\n      <td>99.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "numeric_columns = list(train_data_raw.select_dtypes(include = np.number).columns)\n",
    "train_data_raw[numeric_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sns.set()\n",
    "#sns.pairplot(train_data_raw, vars = ['Age'], hue = 'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_frequencies(data, feature):\n",
    "    '''\n",
    "    Plot frequencie for income <=50k and >50k for a specific feature\n",
    "    '''\n",
    "    \n",
    "    less_50 = data.loc[data['Income'] == '<=50K', feature].value_counts().rename('<=50K')\n",
    "    more_50 = data.loc[data['Income'] == '>50K', feature].value_counts().rename('>50K')\n",
    "    plot_data = pd.concat([less_50, more_50], axis=1).dropna()\n",
    "    plot_data.plot(xlabel = feature, ylabel = 'Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 ID\n",
    "\n",
    "Essa feature contém apenas um número de identificação, ou seja, não é uma feature que faça sentido analisar, e, por isso, será removida durante o tratamento dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "age_data = plot_feature_frequencies(train_data_raw, 'Age')\n",
    "#age_data.plot(xlabel = 'Age', ylabel = 'Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver claramente como a proporção de pessoas que ganham mais que 50 mil aumenta drásticamente com a idade. Entre 20 e 40 anos, há um crescimento acelerado, e a partir daí, a proporção se mantém mais estável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Final Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_feature_frequencies(train_data_raw, 'Final Weight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Education Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_frequencies(train_data_raw, 'Education Num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há dois pontos principais mostrados aqui: primeiramente, todos os indivíduos que ganhavam mais que 50k tem nível de escolaridade maior que 8, ou seja, pelo menos um diploma no nível técnico. Além disso, apenas a partir do nível 14, ou seja, a partir do bacharelado, a propórção de indivíduos que ganahvam mais que 50k superou a dos que ganahvam menos. Logo, grau de escolaridade seria um fator importante para fazer predições em relação à renda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5 Capital Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_frequencies(train_data_raw, 'Capital Gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.6 Capital Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_frequencies(train_data_raw, 'Capital Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.7 Hours per Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_frequencies(train_data_raw, 'Hours per Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse gráfico percebe-se claramente que a maior parte das pessoas possui a jornada padrão de 40h por semana. Porém, quanto mais aumenta-se o número de horas trabalhadas, maior é a proporção de pessoas que ganham mais que 50k, enquanto para valores menores que 40h, a quantidade é bem pequena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dados categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Workclass Education      Marital Status      Occupation Relationship  \\\ncount      30724     32560               32560           30717        32560   \nunique         8        16                   7              14            6   \ntop      Private   HS-grad  Married-civ-spouse  Prof-specialty      Husband   \nfreq       22696     10501               14976            4140        13193   \n\n         Race    Sex Native Country Income  \ncount   32560  32560          31977  32560  \nunique      5      2             41      2  \ntop     White   Male  United-States  <=50K  \nfreq    27815  21789          29169  24719  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Workclass</th>\n      <th>Education</th>\n      <th>Marital Status</th>\n      <th>Occupation</th>\n      <th>Relationship</th>\n      <th>Race</th>\n      <th>Sex</th>\n      <th>Native Country</th>\n      <th>Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>30724</td>\n      <td>32560</td>\n      <td>32560</td>\n      <td>30717</td>\n      <td>32560</td>\n      <td>32560</td>\n      <td>32560</td>\n      <td>31977</td>\n      <td>32560</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>8</td>\n      <td>16</td>\n      <td>7</td>\n      <td>14</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n      <td>41</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>22696</td>\n      <td>10501</td>\n      <td>14976</td>\n      <td>4140</td>\n      <td>13193</td>\n      <td>27815</td>\n      <td>21789</td>\n      <td>29169</td>\n      <td>24719</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "categoric_columns = list(train_data_raw.select_dtypes(exclude = np.number).columns)\n",
    "train_data_raw[categoric_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3 Preparação dos dados\n",
    "\n",
    "### 3.1 Dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing_values(data):\n",
    "    '''\n",
    "    Count missing values for each feature and return a sorted DataFrame with the resuls\n",
    "    '''\n",
    "\n",
    "    missing_count = []\n",
    "    for column in data.columns:\n",
    "        missing_count.append(data[column].isna().sum())\n",
    "    missing_count = np.asarray(missing_count)\n",
    "    missing_count = pd.DataFrame({'feature': data.columns, 'count': missing_count,\n",
    "                                'freq. [%]': 100*missing_count/data.shape[0]}, index=None)\n",
    "    missing_count.sort_values('count', ascending=False, inplace=True, ignore_index=True)\n",
    "    return missing_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_missing_values(train_data_raw).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(original_data, fill_options = None):\n",
    "    '''\n",
    "    Choose what to do with the missing values.\n",
    "    fill_options is a dictionary where de features are keys, and the values are how to fill the missing data, the options are: unknown (fill with 'unknown'), mean (complete with the mean value), moda (complete with most frequent value).\n",
    "    The rest of the missing data will be droped.\n",
    "    '''\n",
    "\n",
    "    data = original_data.copy()\n",
    "    if fill_options is not None:\n",
    "        for feature, action in fill_options.items():\n",
    "            # print(feature, action)\n",
    "            if feature not in data.columns:\n",
    "                # print(feature)\n",
    "                continue\n",
    "            if action == 'unknown':\n",
    "                data[feature].fillna('unknown', inplace=True)\n",
    "            elif action == 'mean':\n",
    "                data[feature].fillna(data[feature].mean(), inplace=True)\n",
    "            elif action == 'moda':\n",
    "                top = data[feature].describe().top\n",
    "                data[feature].fillna(top, inplace=True)\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(32560, 16)\n(30168, 16)\n"
    }
   ],
   "source": [
    "test = handle_missing_values(train_data_raw, {'Occupation': 'unknown'})\n",
    "print(train_data_raw.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tratamento de features\n",
    "seleção, novas, normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_raw, test_raw, fill_options = None, drop_columns = ['ID', 'Education']):\n",
    "    '''\n",
    "    Prepare the data to be used in the classifier\n",
    "    '''\n",
    "\n",
    "    train_data = train_raw.copy()\n",
    "    test_data = test_raw.copy()\n",
    "\n",
    "    # Remove unwanted columns\n",
    "    if drop_columns is not None:\n",
    "        train_data.drop(drop_columns, axis = 1, inplace=True)\n",
    "        test_data.drop(drop_columns, axis = 1, inplace=True)\n",
    "\n",
    "    # Handle the missing values\n",
    "    train_data = handle_missing_values(train_data, fill_options)\n",
    "    test_data = handle_missing_values(test_data, fill_options)\n",
    "\n",
    "    categoric_columns = list(test_data.select_dtypes(exclude = np.number).columns)\n",
    "    label_column = 'Income'\n",
    "\n",
    "    # Encode the categoric feature into numbers\n",
    "    cat_encoder = prep.OrdinalEncoder()\n",
    "    cat_encoder.fit(train_data[categoric_columns])\n",
    "    train_data[categoric_columns] = cat_encoder.transform(train_data[categoric_columns])\n",
    "    test_data[categoric_columns] = cat_encoder.transform(test_data[categoric_columns])\n",
    "\n",
    "    # Encode the labels\n",
    "    label_encoder = prep.LabelEncoder()\n",
    "    Y_train = label_encoder.fit_transform(train_data[label_column])\n",
    "\n",
    "    train_data.drop(label_column, axis = 1, inplace=True)\n",
    "\n",
    "    # Make sure the test and train data have the same number of features\n",
    "    assert train_data.shape[1] == test_data.shape[1]\n",
    "\n",
    "    scaler = prep.StandardScaler()\n",
    "    scaler.fit(train_data)\n",
    "    X_train = scaler.transform(train_data)\n",
    "    X_test = scaler.transform(test_data)\n",
    "\n",
    "    return X_train, Y_train, X_test, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fill_options = {'Occupation': 'unknown', 'Workclass': 'unknown', 'Native Country': 'moda'}\n",
    "drop_columns = ['ID', 'Final Weight', 'Workclass', 'Education', 'Native Country']\n",
    "X_train, Y_train, X_test, label_encoder = prepare_data(train_data_raw, test_data_raw, fill_options, drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X_train shape is (32560, 10)\nY_train shape is (32560,)\nX_test shape is (16280, 10)\n"
    }
   ],
   "source": [
    "print(f'X_train shape is {X_train.shape}')\n",
    "print(f'Y_train shape is {Y_train.shape}')\n",
    "print(f'X_test shape is {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['manhattan'] #, 'chebyshev', 'minkowski']\n",
    "cv_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = (30, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "manhattan with 30 neighbors: 0.8429054054054055\nmanhattan with 31 neighbors: 0.8431511056511056\nmanhattan with 32 neighbors: 0.8429668304668304\nmanhattan with 33 neighbors: 0.8430896805896806\nmanhattan with 34 neighbors: 0.842936117936118\n"
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    for k_value in range(*k_range):\n",
    "        knn_clf = KNeighborsClassifier(k_value, metric = metric)\n",
    "        score = np.mean(cross_val_score(knn_clf, X_train, Y_train, cv=10))\n",
    "        if metric not in cv_scores.keys():\n",
    "            cv_scores[metric] = []\n",
    "        cv_scores[metric].append(score)\n",
    "        print(f'{metric} with {k_value} neighbors: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = pd.DataFrame(cv_scores), index=range(*k_range))\n",
    "knn_results.plot(xlabel='Number of Neighbors', ylabel='CV score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manhattan with 34 neighbors: 0.8448402948402949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "manhattan with 34 neighbors: 0.8448402948402949\n"
    }
   ],
   "source": [
    "metric = 'manhattan'\n",
    "k_value = 34\n",
    "knn_clf = KNeighborsClassifier(k_value, metric = metric)\n",
    "score = np.mean(cross_val_score(knn_clf, X_train, Y_train, cv=10))\n",
    "print(f'{metric} with {k_value} neighbors: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}